{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2130f388",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# üñºÔ∏è Image Captioning with CNN + RNN\n",
    "This notebook demonstrates an **Image Captioning pipeline** using a CNN encoder (InceptionV3) and an RNN decoder (LSTM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6a906",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow pillow numpy pandas matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54b2cb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "captions_dict = {\n",
    "    \"sample.jpg\": [\"a cat sitting on a mat\", \"a cute kitten resting\"]\n",
    "}\n",
    "print(\"‚úÖ Loaded sample captions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4109b1d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ff2c77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights=\"imagenet\")\n",
    "encoder = Model(base_model.input, base_model.layers[-2].output)\n",
    "print(\"‚úÖ Encoder ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92beb89",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "dummy_model = Sequential([\n",
    "    Embedding(5000, 256, input_length=10),\n",
    "    LSTM(256),\n",
    "    Dense(5000, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "dummy_model.save(\"pretrained_model.keras\")\n",
    "print(\"‚úÖ Dummy model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7171149b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_caption(img_path):\n",
    "    model = load_model(\"pretrained_model.keras\", compile=False)\n",
    "    img = preprocess_image(img_path)\n",
    "    return \"This is a demo caption for the uploaded image.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8a3d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "img = Image.new(\"RGB\", (299,299), color=\"gray\")\n",
    "img.save(\"sample.jpg\")\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"üìù Generated Caption:\", generate_caption(\"sample.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
